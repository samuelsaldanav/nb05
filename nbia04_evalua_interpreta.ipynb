{"cells":[{"cell_type":"markdown","source":["# DataLabPro AI - Notebook 04: Evaluaci√≥n e Interpretaci√≥n de Resultados\n","\n","Diagn√≥stico M√©dico por Im√°genes con IA Tradicional"],"metadata":{"id":"s_0INTlwL7J2"}},{"cell_type":"markdown","source":["Notebook 04: Evaluaci√≥n e Interpretaci√≥n\n","\n","‚úÖ Evaluaci√≥n exhaustiva en conjunto de test\n","\n","‚úÖ M√©tricas cl√≠nicas detalladas\n","\n","‚úÖ Interpretabilidad con Grad-CAM\n","\n","‚úÖ An√°lisis de casos dif√≠ciles\n","\n","‚úÖ Reporte cl√≠nico automatizado"],"metadata":{"id":"k7GXiEqGJ-YV"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Kdzgj4cBbHTL"}},{"cell_type":"markdown","source":["----------"],"metadata":{"id":"DFKc7Mr0nCkc"}},{"cell_type":"code","source":["# Montar drive\n","\n","from google.colab import drive\n","import os\n","\n","if not os.path.ismount('/content/drive'):\n","    drive.mount('/content/drive')"],"metadata":{"id":"6JKtmzyF_n9R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5ef64bc-e605-43e3-ef37-178482cb20c6","executionInfo":{"status":"ok","timestamp":1757106743574,"user_tz":300,"elapsed":70101,"user":{"displayName":"Developer Scientist","userId":"05267242669480320119"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","DataLabPro AI - Notebook 04: Evaluaci√≥n e Interpretaci√≥n de Resultados\n","Diagn√≥stico M√©dico por Im√°genes con IA Tradicional\n","\n","Autor: DataLabPro Team\n","Fecha: 2025\n","Objetivo: Evaluar rendimiento del mejor modelo y generar interpretaciones cl√≠nicas\n","\"\"\"\n","\n","#@title ## üìä Visualizaciones de Resultados - FUNCIONES FALTANTES Y CORRECCIONES\n","\n","def create_confusion_matrix_plot(y_true, y_pred, class_names):\n","    \"\"\"Crear matriz de confusi√≥n interactiva\"\"\"\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    # Normalizar matriz de confusi√≥n\n","    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    # Crear figura con subplots\n","    fig = make_subplots(\n","        rows=1, cols=2,\n","        subplot_titles=['Matriz de Confusi√≥n (Conteos)', 'Matriz de Confusi√≥n (Normalizada)'],\n","        specs=[[{'type': 'heatmap'}, {'type': 'heatmap'}]]\n","    )\n","\n","    # Matriz de confusi√≥n con conteos\n","    fig.add_trace(\n","        go.Heatmap(\n","            z=cm,\n","            x=class_names,\n","            y=class_names,\n","            colorscale='Blues',\n","            text=cm,\n","            texttemplate=\"%{text}\",\n","            textfont={\"size\": 12},\n","            showscale=True,\n","            colorbar=dict(x=0.45),\n","            name=\"Conteos\"\n","        ),\n","        row=1, col=1\n","    )\n","\n","    # Matriz de confusi√≥n normalizada\n","    fig.add_trace(\n","        go.Heatmap(\n","            z=cm_normalized,\n","            x=class_names,\n","            y=class_names,\n","            colorscale='Reds',\n","            text=np.round(cm_normalized, 3),\n","            texttemplate=\"%{text}\",\n","            textfont={\"size\": 12},\n","            showscale=True,\n","            colorbar=dict(x=1.0),\n","            name=\"Normalizada\"\n","        ),\n","        row=1, col=2\n","    )\n","\n","    # Actualizar layout\n","    fig.update_layout(\n","        title=\"An√°lisis de Matriz de Confusi√≥n\",\n","        height=500,\n","        width=1000,\n","        showlegend=False\n","    )\n","\n","    fig.update_xaxes(title_text=\"Predicci√≥n\", row=1, col=1)\n","    fig.update_yaxes(title_text=\"Real\", row=1, col=1)\n","    fig.update_xaxes(title_text=\"Predicci√≥n\", row=1, col=2)\n","    fig.update_yaxes(title_text=\"Real\", row=1, col=2)\n","\n","    # Crear directorio si no existe\n","    os.makedirs(f'{RESULTS_PATH}/visualizations', exist_ok=True)\n","\n","    # Guardar y mostrar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/confusion_matrix.html')\n","    fig.show()\n","\n","    print(f\"üìä Matriz de confusi√≥n guardada en: {RESULTS_PATH}/visualizations/confusion_matrix.html\")\n","\n","def create_roc_curves(y_true_categorical, y_pred_proba, class_names):\n","    \"\"\"Crear curvas ROC para cada clase\"\"\"\n","\n","    fig = go.Figure()\n","\n","    # Si es binario, tratar de forma especial\n","    if len(class_names) == 2:\n","        # Problema binario\n","        fpr, tpr, _ = roc_curve(y_true_categorical[:, 1], y_pred_proba[:, 1])\n","        roc_auc = auc(fpr, tpr)\n","\n","        fig.add_trace(go.Scatter(\n","            x=fpr, y=tpr,\n","            mode='lines',\n","            name=f'{class_names[1]} vs {class_names[0]} (AUC = {roc_auc:.3f})',\n","            line=dict(width=3)\n","        ))\n","    else:\n","        # Problema multiclase - One-vs-Rest\n","        for i, class_name in enumerate(class_names):\n","            try:\n","                fpr, tpr, _ = roc_curve(y_true_categorical[:, i], y_pred_proba[:, i])\n","                roc_auc = auc(fpr, tpr)\n","\n","                fig.add_trace(go.Scatter(\n","                    x=fpr, y=tpr,\n","                    mode='lines',\n","                    name=f'{class_name} (AUC = {roc_auc:.3f})',\n","                    line=dict(width=2)\n","                ))\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Error calculando ROC para {class_name}: {e}\")\n","                continue\n","\n","    # L√≠nea diagonal de referencia\n","    fig.add_trace(go.Scatter(\n","        x=[0, 1], y=[0, 1],\n","        mode='lines',\n","        name='Random Classifier',\n","        line=dict(dash='dash', color='gray', width=1)\n","    ))\n","\n","    fig.update_layout(\n","        title='Curvas ROC por Clase',\n","        xaxis_title='Tasa de Falsos Positivos (1 - Especificidad)',\n","        yaxis_title='Tasa de Verdaderos Positivos (Sensibilidad)',\n","        width=800,\n","        height=600,\n","        xaxis=dict(range=[0, 1]),\n","        yaxis=dict(range=[0, 1])\n","    )\n","\n","    # Crear directorio si no existe\n","    os.makedirs(f'{RESULTS_PATH}/visualizations', exist_ok=True)\n","\n","    # Guardar y mostrar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/roc_curves.html')\n","    fig.show()\n","\n","    print(f\"üìà Curvas ROC guardadas en: {RESULTS_PATH}/visualizations/roc_curves.html\")\n","\n","def create_metrics_dashboard(metrics, class_names):\n","    \"\"\"Crear dashboard de m√©tricas\"\"\"\n","\n","    # Preparar datos para visualizaci√≥n\n","    metrics_data = []\n","\n","    for class_name in class_names:\n","        metrics_data.append({\n","            'Clase': class_name,\n","            'Precisi√≥n': metrics[f'precision_{class_name}'],\n","            'Recall': metrics[f'recall_{class_name}'],\n","            'F1-Score': metrics[f'f1_{class_name}']\n","        })\n","\n","    df_metrics = pd.DataFrame(metrics_data)\n","\n","    # Crear gr√°fico de barras agrupadas\n","    fig = go.Figure()\n","\n","    x = df_metrics['Clase']\n","\n","    fig.add_trace(go.Bar(\n","        name='Precisi√≥n',\n","        x=x,\n","        y=df_metrics['Precisi√≥n'],\n","        marker_color='lightblue',\n","        text=np.round(df_metrics['Precisi√≥n'], 3),\n","        textposition='auto'\n","    ))\n","\n","    fig.add_trace(go.Bar(\n","        name='Recall (Sensibilidad)',\n","        x=x,\n","        y=df_metrics['Recall'],\n","        marker_color='lightcoral',\n","        text=np.round(df_metrics['Recall'], 3),\n","        textposition='auto'\n","    ))\n","\n","    fig.add_trace(go.Bar(\n","        name='F1-Score',\n","        x=x,\n","        y=df_metrics['F1-Score'],\n","        marker_color='lightgreen',\n","        text=np.round(df_metrics['F1-Score'], 3),\n","        textposition='auto'\n","    ))\n","\n","    # Agregar l√≠neas de referencia\n","    fig.add_hline(y=0.8, line_dash=\"dash\", line_color=\"red\",\n","                  annotation_text=\"Meta Cl√≠nica (0.8)\")\n","    fig.add_hline(y=0.9, line_dash=\"dash\", line_color=\"orange\",\n","                  annotation_text=\"Excelencia Cl√≠nica (0.9)\")\n","\n","    fig.update_layout(\n","        title='M√©tricas de Rendimiento por Clase',\n","        xaxis_title='Clase',\n","        yaxis_title='Score',\n","        barmode='group',\n","        height=500,\n","        width=800,\n","        yaxis=dict(range=[0, 1.1]),\n","        legend=dict(\n","            orientation=\"h\",\n","            yanchor=\"bottom\",\n","            y=1.02,\n","            xanchor=\"right\",\n","            x=1\n","        )\n","    )\n","\n","    # Crear directorio si no existe\n","    os.makedirs(f'{RESULTS_PATH}/visualizations', exist_ok=True)\n","\n","    # Guardar y mostrar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/metrics_dashboard.html')\n","    fig.show()\n","\n","    print(f\"üìä Dashboard de m√©tricas guardado en: {RESULTS_PATH}/visualizations/metrics_dashboard.html\")\n","\n","def create_precision_recall_curves(y_true_categorical, y_pred_proba, class_names):\n","    \"\"\"Crear curvas Precisi√≥n-Recall para cada clase\"\"\"\n","\n","    fig = go.Figure()\n","\n","    for i, class_name in enumerate(class_names):\n","        try:\n","            precision, recall, _ = precision_recall_curve(y_true_categorical[:, i], y_pred_proba[:, i])\n","            avg_precision = average_precision_score(y_true_categorical[:, i], y_pred_proba[:, i])\n","\n","            fig.add_trace(go.Scatter(\n","                x=recall, y=precision,\n","                mode='lines',\n","                name=f'{class_name} (AP = {avg_precision:.3f})',\n","                line=dict(width=2)\n","            ))\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Error calculando Precisi√≥n-Recall para {class_name}: {e}\")\n","            continue\n","\n","    # L√≠nea de referencia random\n","    baseline = np.sum(y_true_categorical, axis=0) / len(y_true_categorical)\n","    for i, class_name in enumerate(class_names):\n","        fig.add_hline(y=baseline[i], line_dash=\"dash\", line_color=\"gray\",\n","                      annotation_text=f\"Baseline {class_name} ({baseline[i]:.3f})\")\n","\n","    fig.update_layout(\n","        title='Curvas Precisi√≥n-Recall por Clase',\n","        xaxis_title='Recall (Sensibilidad)',\n","        yaxis_title='Precisi√≥n (VPP)',\n","        width=800,\n","        height=600,\n","        xaxis=dict(range=[0, 1]),\n","        yaxis=dict(range=[0, 1])\n","    )\n","\n","    # Guardar y mostrar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/precision_recall_curves.html')\n","    fig.show()\n","\n","    print(f\"üìà Curvas Precisi√≥n-Recall guardadas en: {RESULTS_PATH}/visualizations/precision_recall_curves.html\")\n","\n","def create_class_distribution_comparison(y_true, y_pred, class_names):\n","    \"\"\"Comparar distribuci√≥n de clases real vs predicha\"\"\"\n","\n","    # Contar distribuciones\n","    true_counts = [np.sum(y_true == i) for i in range(len(class_names))]\n","    pred_counts = [np.sum(y_pred == i) for i in range(len(class_names))]\n","\n","    fig = go.Figure()\n","\n","    fig.add_trace(go.Bar(\n","        name='Real',\n","        x=class_names,\n","        y=true_counts,\n","        marker_color='skyblue',\n","        text=true_counts,\n","        textposition='auto'\n","    ))\n","\n","    fig.add_trace(go.Bar(\n","        name='Predicho',\n","        x=class_names,\n","        y=pred_counts,\n","        marker_color='lightcoral',\n","        text=pred_counts,\n","        textposition='auto'\n","    ))\n","\n","    fig.update_layout(\n","        title='Distribuci√≥n de Clases: Real vs Predicha',\n","        xaxis_title='Clase',\n","        yaxis_title='N√∫mero de Muestras',\n","        barmode='group',\n","        height=500,\n","        width=700\n","    )\n","\n","    # Guardar y mostrar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/class_distribution.html')\n","    fig.show()\n","\n","    print(f\"üìä Distribuci√≥n de clases guardada en: {RESULTS_PATH}/visualizations/class_distribution.html\")\n","\n","# Crear visualizaciones completas\n","print(\"\\nüìä Creando visualizaciones completas de evaluaci√≥n...\")\n","\n","try:\n","    # Matriz de confusi√≥n\n","    create_confusion_matrix_plot(\n","        evaluation_results['y_true'],\n","        evaluation_results['y_pred'],\n","        case_config['classes']\n","    )\n","\n","    # Preparar y_true_categorical correctamente\n","    if use_test_generator:\n","        y_true_cat = tf.keras.utils.to_categorical(evaluation_results['y_true'], len(case_config['classes']))\n","    else:\n","        y_true_cat = y_test\n","\n","    # Curvas ROC\n","    create_roc_curves(y_true_cat, evaluation_results['y_pred_proba'], case_config['classes'])\n","\n","    # Dashboard de m√©tricas\n","    create_metrics_dashboard(evaluation_results['metrics'], case_config['classes'])\n","\n","    # Curvas Precisi√≥n-Recall\n","    create_precision_recall_curves(y_true_cat, evaluation_results['y_pred_proba'], case_config['classes'])\n","\n","    # Distribuci√≥n de clases\n","    create_class_distribution_comparison(evaluation_results['y_true'], evaluation_results['y_pred'], case_config['classes'])\n","\n","    print(\"‚úÖ Todas las visualizaciones creadas exitosamente!\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error creando visualizaciones: {str(e)}\")\n","    print(\"Continuando con el resto del notebook...\")\n","\n","#@title ## üîç Interpretabilidad con Grad-CAM - VERSION MEJORADA\n","\n","class GradCAMVisualizer:\n","    \"\"\"Clase mejorada para generar visualizaciones Grad-CAM\"\"\"\n","\n","    def __init__(self, model, class_names):\n","        self.model = model\n","        self.class_names = class_names\n","        self.target_layers = self._find_target_layers()\n","\n","    def _find_target_layers(self):\n","        \"\"\"Encontrar capas objetivo para Grad-CAM\"\"\"\n","        target_layers = []\n","\n","        for layer in reversed(self.model.layers):\n","            # Buscar capas convolucionales\n","            if 'conv' in layer.name.lower() or isinstance(layer, tf.keras.layers.Conv2D):\n","                target_layers.append(layer.name)\n","            # Tambi√©n considerar capas de activaci√≥n despu√©s de convolucionales\n","            elif hasattr(layer, 'activation') and len(layer.output.shape) == 4:\n","                target_layers.append(layer.name)\n","\n","        return target_layers[:3]  # Tomar las 3 mejores capas\n","\n","    def generate_gradcam(self, image, class_index, layer_name=None):\n","        \"\"\"Generar visualizaci√≥n Grad-CAM mejorada\"\"\"\n","\n","        try:\n","            # Seleccionar capa objetivo\n","            if layer_name is None and self.target_layers:\n","                layer_name = self.target_layers[0]\n","            elif layer_name is None:\n","                print(\"‚ö†Ô∏è No se encontraron capas adecuadas para Grad-CAM\")\n","                return None\n","\n","            # Verificar que la capa existe\n","            try:\n","                target_layer = self.model.get_layer(layer_name)\n","            except ValueError:\n","                print(f\"‚ö†Ô∏è Capa '{layer_name}' no encontrada\")\n","                return None\n","\n","            # Crear modelo Grad-CAM\n","            grad_model = keras.Model(\n","                inputs=self.model.inputs,\n","                outputs=[target_layer.output, self.model.output]\n","            )\n","\n","            # Asegurar que la imagen tiene la forma correcta\n","            if len(image.shape) == 3:\n","                image_batch = np.expand_dims(image, axis=0)\n","            else:\n","                image_batch = image\n","\n","            # Calcular gradientes\n","            with tf.GradientTape() as tape:\n","                conv_outputs, predictions = grad_model(image_batch)\n","                if len(predictions.shape) > 1:\n","                    loss = predictions[:, class_index]\n","                else:\n","                    loss = predictions[class_index]\n","\n","            # Obtener gradientes\n","            grads = tape.gradient(loss, conv_outputs)\n","\n","            if grads is None:\n","                print(\"‚ö†Ô∏è No se pudieron calcular gradientes\")\n","                return None\n","\n","            # Calcular pesos Grad-CAM\n","            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","            # Generar heatmap\n","            conv_outputs = conv_outputs[0] if len(conv_outputs.shape) > 3 else conv_outputs\n","            heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n","            heatmap = tf.squeeze(heatmap)\n","\n","            # Normalizar heatmap\n","            heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)\n","\n","            return heatmap.numpy()\n","\n","        except Exception as e:\n","            print(f\"‚ùå Error generando Grad-CAM: {str(e)}\")\n","            return None\n","\n","    def visualize_gradcam_samples(self, images, true_labels, predictions, file_paths=None, num_samples=6):\n","        \"\"\"Visualizar Grad-CAM para muestras seleccionadas con mejor organizaci√≥n\"\"\"\n","\n","        # Seleccionar muestras representativas\n","        samples_to_show = self._select_representative_samples(\n","            true_labels, predictions, num_samples\n","        )\n","\n","        if not samples_to_show:\n","            print(\"‚ö†Ô∏è No se pudieron seleccionar muestras para Grad-CAM\")\n","            return\n","\n","        # Crear visualizaci√≥n mejorada\n","        fig, axes = plt.subplots(len(samples_to_show), 4, figsize=(20, 5 * len(samples_to_show)))\n","        if len(samples_to_show) == 1:\n","            axes = axes.reshape(1, -1)\n","\n","        for idx, sample_idx in enumerate(samples_to_show):\n","            image = images[sample_idx]\n","            true_class_idx = np.argmax(true_labels[sample_idx]) if len(true_labels[sample_idx].shape) > 0 else true_labels[sample_idx]\n","            pred_class_idx = np.argmax(predictions[sample_idx])\n","\n","            true_class = self.class_names[true_class_idx]\n","            pred_class = self.class_names[pred_class_idx]\n","            confidence = predictions[sample_idx, pred_class_idx]\n","\n","            # Determinar si la predicci√≥n es correcta\n","            is_correct = true_class_idx == pred_class_idx\n","            color = 'green' if is_correct else 'red'\n","\n","            # 1. Imagen original\n","            axes[idx, 0].imshow(image)\n","            axes[idx, 0].set_title(\n","                f'Original\\n{true_class} ‚Üí {pred_class}\\nConf: {confidence:.3f}',\n","                color=color, fontsize=10\n","            )\n","            axes[idx, 0].axis('off')\n","\n","            # 2. Grad-CAM para clase predicha\n","            heatmap_pred = self.generate_gradcam(image, pred_class_idx)\n","            if heatmap_pred is not None:\n","                # Redimensionar heatmap\n","                heatmap_resized = cv2.resize(heatmap_pred, (image.shape[1], image.shape[0]))\n","\n","                # Superposici√≥n\n","                axes[idx, 1].imshow(image)\n","                im1 = axes[idx, 1].imshow(heatmap_resized, cmap='jet', alpha=0.4)\n","                axes[idx, 1].set_title(f'Grad-CAM: {pred_class}')\n","\n","                # Agregar colorbar\n","                plt.colorbar(im1, ax=axes[idx, 1], fraction=0.046, pad=0.04)\n","            else:\n","                axes[idx, 1].imshow(image)\n","                axes[idx, 1].set_title('Grad-CAM no disponible')\n","            axes[idx, 1].axis('off')\n","\n","            # 3. Grad-CAM para clase real (si es diferente)\n","            if true_class_idx != pred_class_idx:\n","                heatmap_true = self.generate_gradcam(image, true_class_idx)\n","                if heatmap_true is not None:\n","                    heatmap_resized = cv2.resize(heatmap_true, (image.shape[1], image.shape[0]))\n","                    axes[idx, 2].imshow(image)\n","                    im2 = axes[idx, 2].imshow(heatmap_resized, cmap='jet', alpha=0.4)\n","                    axes[idx, 2].set_title(f'Grad-CAM: {true_class}')\n","                    plt.colorbar(im2, ax=axes[idx, 2], fraction=0.046, pad=0.04)\n","                else:\n","                    axes[idx, 2].imshow(image)\n","                    axes[idx, 2].set_title('Grad-CAM no disponible')\n","            else:\n","                # Solo mostrar el heatmap puro\n","                if heatmap_pred is not None:\n","                    im2 = axes[idx, 2].imshow(heatmap_pred, cmap='jet')\n","                    axes[idx, 2].set_title('Mapa de Activaci√≥n')\n","                    plt.colorbar(im2, ax=axes[idx, 2], fraction=0.046, pad=0.04)\n","                else:\n","                    axes[idx, 2].axis('off')\n","            axes[idx, 2].axis('off')\n","\n","            # 4. Distribuci√≥n de probabilidades\n","            probs = predictions[sample_idx]\n","            bars = axes[idx, 3].bar(range(len(self.class_names)), probs,\n","                                   color=['red' if i == pred_class_idx else 'lightblue'\n","                                         for i in range(len(self.class_names))])\n","\n","            # Resaltar la clase real con borde\n","            if true_class_idx < len(bars):\n","                bars[true_class_idx].set_edgecolor('green')\n","                bars[true_class_idx].set_linewidth(3)\n","\n","            axes[idx, 3].set_title('Probabilidades')\n","            axes[idx, 3].set_xticks(range(len(self.class_names)))\n","            axes[idx, 3].set_xticklabels(self.class_names, rotation=45, ha='right')\n","            axes[idx, 3].set_ylim([0, 1])\n","\n","            # Agregar l√≠nea de confianza\n","            axes[idx, 3].axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)\n","\n","        plt.tight_layout()\n","\n","        # Crear directorio si no existe\n","        os.makedirs(f'{RESULTS_PATH}/visualizations', exist_ok=True)\n","\n","        plt.savefig(f'{RESULTS_PATH}/visualizations/gradcam_analysis.png', dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        print(f\"üîç An√°lisis Grad-CAM guardado en: {RESULTS_PATH}/visualizations/gradcam_analysis.png\")\n","\n","    def _select_representative_samples(self, true_labels, predictions, num_samples):\n","        \"\"\"Seleccionar muestras representativas para an√°lisis\"\"\"\n","\n","        true_classes = np.argmax(true_labels, axis=1) if len(true_labels.shape) > 1 else true_labels\n","        pred_classes = np.argmax(predictions, axis=1)\n","\n","        samples = []\n","\n","        # 1. Casos correctos con alta confianza\n","        correct_mask = true_classes == pred_classes\n","        if np.any(correct_mask):\n","            correct_indices = np.where(correct_mask)[0]\n","            max_probs = np.max(predictions, axis=1)\n","            high_conf_correct = correct_indices[np.argsort(max_probs[correct_indices])[-2:]]\n","            samples.extend(high_conf_correct)\n","\n","        # 2. Casos incorrectos con alta confianza (errores confiados)\n","        incorrect_mask = true_classes != pred_classes\n","        if np.any(incorrect_mask):\n","            incorrect_indices = np.where(incorrect_mask)[0]\n","            max_probs = np.max(predictions, axis=1)\n","            high_conf_incorrect = incorrect_indices[np.argsort(max_probs[incorrect_indices])[-2:]]\n","            samples.extend(high_conf_incorrect)\n","\n","        # 3. Casos con baja confianza\n","        max_probs = np.max(predictions, axis=1)\n","        low_conf_indices = np.where(max_probs < 0.7)[0]\n","        if len(low_conf_indices) > 0:\n","            samples.extend(np.random.choice(low_conf_indices,\n","                                          min(2, len(low_conf_indices)),\n","                                          replace=False))\n","\n","        # Completar con muestras aleatorias si es necesario\n","        remaining = num_samples - len(samples)\n","        if remaining > 0:\n","            all_indices = set(range(len(predictions)))\n","            available = list(all_indices - set(samples))\n","            if available:\n","                samples.extend(np.random.choice(available,\n","                                              min(remaining, len(available)),\n","                                              replace=False))\n","\n","        return samples[:num_samples]\n","\n","# Crear visualizador Grad-CAM mejorado\n","print(\"\\nüîç Creando visualizaciones Grad-CAM para interpretabilidad...\")\n","\n","try:\n","    gradcam_visualizer = GradCAMVisualizer(best_model, case_config['classes'])\n","\n","    # Generar visualizaciones Grad-CAM\n","    if not use_test_generator and X_test is not None:\n","        # Seleccionar subconjunto para Grad-CAM\n","        num_samples = min(8, len(X_test))\n","        gradcam_visualizer.visualize_gradcam_samples(\n","            X_test, y_test, evaluation_results['y_pred_proba'],\n","            test_file_paths, num_samples\n","        )\n","    else:\n","        print(\"‚ö†Ô∏è Grad-CAM requiere arrays numpy. Implementando versi√≥n alternativa...\")\n","\n","        # Alternativa para generadores\n","        if test_generator is not None:\n","            test_generator.reset()\n","            batch_images, batch_labels = test_generator.next()\n","            sample_predictions = best_model.predict(batch_images[:6])\n","\n","            gradcam_visualizer.visualize_gradcam_samples(\n","                batch_images[:6], batch_labels[:6], sample_predictions\n","            )\n","\n","except Exception as e:\n","    print(f\"‚ùå Error en Grad-CAM: {str(e)}\")\n","    print(\"Continuando sin visualizaciones Grad-CAM...\")\n","\n","#@title ## üìã An√°lisis de Casos Dif√≠ciles - MEJORADO\n","\n","def analyze_difficult_cases(y_true, y_pred, y_pred_proba, class_names, threshold=0.7):\n","    \"\"\"An√°lisis completo de casos problem√°ticos\"\"\"\n","\n","    print(\"\\nüîç AN√ÅLISIS COMPLETO DE CASOS DIF√çCILES\")\n","    print(\"=\" * 60)\n","\n","    # M√©tricas b√°sicas\n","    max_proba = np.max(y_pred_proba, axis=1)\n","    low_confidence_cases = np.where(max_proba < threshold)[0]\n","    incorrect_cases = np.where(y_true != y_pred)[0]\n","\n","    total_samples = len(y_true)\n","    low_conf_pct = (len(low_confidence_cases) / total_samples) * 100\n","    error_pct = (len(incorrect_cases) / total_samples) * 100\n","\n","    print(f\"üìä RESUMEN GENERAL:\")\n","    print(f\"  Total de muestras: {total_samples}\")\n","    print(f\"  Casos con confianza < {threshold}: {len(low_confidence_cases)} ({low_conf_pct:.1f}%)\")\n","    print(f\"  Predicciones incorrectas: {len(incorrect_cases)} ({error_pct:.1f}%)\")\n","\n","    # Casos cr√≠ticos (incorrectos con alta confianza)\n","    critical_cases = np.intersect1d(\n","        incorrect_cases,\n","        np.where(max_proba >= 0.8)[0]\n","    )\n","    print(f\"  üö® Casos cr√≠ticos (error + alta confianza): {len(critical_cases)}\")\n","\n","    # An√°lisis por clase\n","    print(f\"\\nüìà AN√ÅLISIS DETALLADO POR CLASE:\")\n","    class_analysis = {}\n","\n","    for i, class_name in enumerate(class_names):\n","        class_mask = y_true == i\n","        class_total = np.sum(class_mask)\n","\n","        if class_total == 0:\n","            continue\n","\n","        class_correct = np.sum((y_true == y_pred) & class_mask)\n","        class_accuracy = class_correct / class_total\n","\n","        # Casos problem√°ticos de esta clase\n","        class_low_conf = np.sum(class_mask & (max_proba < threshold))\n","        class_false_neg = np.sum(class_mask & (y_pred != i))  # Falsos negativos\n","        class_false_pos = np.sum((y_pred == i) & (y_true != i))  # Falsos positivos\n","\n","        # Confianza promedio para esta clase\n","        class_probs = y_pred_proba[class_mask, i]\n","        avg_confidence = np.mean(class_probs) if len(class_probs) > 0 else 0\n","\n","        class_analysis[class_name] = {\n","            'total': class_total,\n","            'correct': class_correct,\n","            'accuracy': class_accuracy,\n","            'low_confidence': class_low_conf,\n","            'false_negatives': class_false_neg,\n","            'false_positives': class_false_pos,\n","            'avg_confidence': avg_confidence\n","        }\n","\n","        print(f\"\\n  üè∑Ô∏è {class_name.upper()}:\")\n","        print(f\"    Total: {class_total} | Correctos: {class_correct} | Precisi√≥n: {class_accuracy:.3f}\")\n","        print(f\"    Baja confianza: {class_low_conf} | Falsos negativos: {class_false_neg}\")\n","        print(f\"    Falsos positivos: {class_false_pos} | Confianza promedio: {avg_confidence:.3f}\")\n","\n","        # Alertas espec√≠ficas\n","        if class_accuracy < 0.8:\n","            print(f\"    ‚ö†Ô∏è ALERTA: Precisi√≥n baja para {class_name}\")\n","        if class_false_neg > class_total * 0.15:  # >15% falsos negativos\n","            print(f\"    üö® CR√çTICO: Alto √≠ndice de falsos negativos para {class_name}\")\n","\n","    # An√°lisis de patrones de error\n","    print(f\"\\nüîÑ PATRONES DE ERRORES M√ÅS FRECUENTES:\")\n","    if len(incorrect_cases) > 0:\n","        error_patterns = {}\n","        for idx in incorrect_cases:\n","            true_class = class_names[y_true[idx]]\n","            pred_class = class_names[y_pred[idx]]\n","            pattern = f\"{true_class} ‚Üí {pred_class}\"\n","            error_patterns[pattern] = error_patterns.get(pattern, 0) + 1\n","\n","        # Ordenar por frecuencia\n","        sorted_errors = sorted(error_patterns.items(), key=lambda x: x[1], reverse=True)\n","        for pattern, count in sorted_errors[:5]:  # Top 5 errores\n","            percentage = (count / len(incorrect_cases)) * 100\n","            print(f\"  {pattern}: {count} casos ({percentage:.1f}% de errores)\")\n","\n","    # An√°lisis de confianza por rangos\n","    print(f\"\\nüìä DISTRIBUCI√ìN DE CONFIANZA:\")\n","    confidence_ranges = [\n","        (0.0, 0.5, \"Muy baja\"),\n","        (0.5, 0.7, \"Baja\"),\n","        (0.7, 0.8, \"Media\"),\n","        (0.8, 0.9, \"Alta\"),\n","        (0.9, 1.0, \"Muy alta\")\n","    ]\n","\n","    for min_conf, max_conf, label in confidence_ranges:\n","        range_mask = (max_proba >= min_conf) & (max_proba < max_conf)\n","        range_count = np.sum(range_mask)\n","        range_accuracy = np.mean(y_true[range_mask] == y_pred[range_mask]) if range_count > 0 else 0\n","        range_pct = (range_count / total_samples) * 100\n","\n","        print(f\"  {label} ({min_conf}-{max_conf}): {range_count} casos ({range_pct:.1f}%) - Precisi√≥n: {range_accuracy:.3f}\")\n","\n","    # Recomendaciones espec√≠ficas\n","    print(f\"\\nüí° RECOMENDACIONES BASADAS EN EL AN√ÅLISIS:\")\n","    recommendations = []\n","\n","    if low_conf_pct > 20:\n","        recommendations.append(\"Alto porcentaje de casos con baja confianza - considerar ensemble de modelos\")\n","\n","    if len(critical_cases) > total_samples * 0.05:  # >5% casos cr√≠ticos\n","        recommendations.append(\"Casos cr√≠ticos detectados - revisar arquitectura del modelo\")\n","\n","    # Recomendaciones por clase\n","    for class_name, analysis in class_analysis.items():\n","        if analysis['false_negatives'] > analysis['total'] * 0.15:\n","            recommendations.append(f\"Mejorar detecci√≥n de clase '{class_name}' - muchos falsos negativos\")\n","        if analysis['avg_confidence'] < 0.6:\n","            recommendations.append(f\"Baja confianza en clase '{class_name}' - revisar datos de entrenamiento\")\n","\n","    if recommendations:\n","        for i, rec in enumerate(recommendations, 1):\n","            print(f\"  {i}. {rec}\")\n","    else:\n","        print(\"  ‚úÖ No se detectaron problemas cr√≠ticos en el modelo\")\n","\n","    return {\n","        'low_confidence_cases': low_confidence_cases,\n","        'incorrect_cases': incorrect_cases,\n","        'critical_cases': critical_cases,\n","        'error_patterns': error_patterns if len(incorrect_cases) > 0 else {},\n","        'class_analysis': class_analysis,\n","        'recommendations': recommendations\n","    }\n","\n","def create_confidence_distribution_plot(y_pred_proba, y_true, y_pred, class_names):\n","    \"\"\"Crear an√°lisis completo de distribuci√≥n de confianza\"\"\"\n","\n","    max_proba = np.max(y_pred_proba, axis=1)\n","    correct_mask = y_true == y_pred\n","\n","    # Crear figura con m√∫ltiples subplots\n","    fig = make_subplots(\n","        rows=2, cols=2,\n","        subplot_titles=[\n","            'Distribuci√≥n General de Confianza',\n","            'Confianza por Clase Predicha',\n","            'Confianza vs Precisi√≥n',\n","            'Casos Problem√°ticos'\n","        ],\n","        specs=[[{'type': 'histogram'}, {'type': 'box'}],\n","               [{'type': 'scatter'}, {'type': 'bar'}]]\n","    )\n","\n","    # 1. Distribuci√≥n general\n","    fig.add_trace(go.Histogram(\n","        x=max_proba[correct_mask],\n","        name='Correctas',\n","        opacity=0.7,\n","        nbinsx=20,\n","        marker_color='green',\n","        legendgroup='correct'\n","    ), row=1, col=1)\n","\n","    fig.add_trace(go.Histogram(\n","        x=max_proba[~correct_mask],\n","        name='Incorrectas',\n","        opacity=0.7,\n","        nbinsx=20,\n","        marker_color='red',\n","        legendgroup='incorrect'\n","    ), row=1, col=1)\n","\n","    # L√≠neas de referencia\n","    fig.add_vline(x=0.5, line_dash=\"dash\", line_color=\"gray\", row=1, col=1)\n","    fig.add_vline(x=0.7, line_dash=\"dash\", line_color=\"blue\", row=1, col=1)\n","    fig.add_vline(x=0.9, line_dash=\"dash\", line_color=\"orange\", row=1, col=1)\n","\n","    # 2. Box plots por clase predicha\n","    pred_classes = np.argmax(y_pred_proba, axis=1)\n","    for i, class_name in enumerate(class_names):\n","        class_mask = pred_classes == i\n","        if np.any(class_mask):\n","            fig.add_trace(go.Box(\n","                y=max_proba[class_mask],\n","                name=class_name,\n","                boxpoints='outliers'\n","            ), row=1, col=2)\n","\n","    # 3. Confianza vs precisi√≥n por bins\n","    confidence_bins = np.linspace(0, 1, 11)\n","    bin_centers = (confidence_bins[:-1] + confidence_bins[1:]) / 2\n","    bin_accuracies = []\n","    bin_counts = []\n","\n","    for i in range(len(confidence_bins)-1):\n","        bin_mask = (max_proba >= confidence_bins[i]) & (max_proba < confidence_bins[i+1])\n","        if np.any(bin_mask):\n","            bin_accuracy = np.mean(correct_mask[bin_mask])\n","            bin_count = np.sum(bin_mask)\n","        else:\n","            bin_accuracy = 0\n","            bin_count = 0\n","        bin_accuracies.append(bin_accuracy)\n","        bin_counts.append(bin_count)\n","\n","    fig.add_trace(go.Scatter(\n","        x=bin_centers,\n","        y=bin_accuracies,\n","        mode='lines+markers',\n","        name='Precisi√≥n por Confianza',\n","        line=dict(width=3),\n","        marker=dict(size=8)\n","    ), row=2, col=1)\n","\n","    # L√≠nea de calibraci√≥n perfecta\n","    fig.add_trace(go.Scatter(\n","        x=[0, 1],\n","        y=[0, 1],\n","        mode='lines',\n","        name='Calibraci√≥n Perfecta',\n","        line=dict(dash='dash', color='gray')\n","    ), row=2, col=1)\n","\n","    # 4. An√°lisis de casos problem√°ticos\n","    problem_categories = ['Muy Baja (<0.5)', 'Baja (0.5-0.7)', 'Errores Alta Conf (>0.8)']\n","    problem_counts = [\n","        np.sum(max_proba < 0.5),\n","        np.sum((max_proba >= 0.5) & (max_proba < 0.7)),\n","        np.sum((max_proba >= 0.8) & ~correct_mask)\n","    ]\n","\n","    colors = ['red', 'orange', 'darkred']\n","    fig.add_trace(go.Bar(\n","        x=problem_categories,\n","        y=problem_counts,\n","        marker_color=colors,\n","        text=problem_counts,\n","        textposition='auto'\n","    ), row=2, col=2)\n","\n","    # Actualizar layout\n","    fig.update_layout(\n","        title='An√°lisis Completo de Confianza del Modelo',\n","        height=800,\n","        width=1200,\n","        showlegend=True\n","    )\n","\n","    fig.update_xaxes(title_text=\"Confianza M√°xima\", row=1, col=1)\n","    fig.update_yaxes(title_text=\"Frecuencia\", row=1, col=1)\n","    fig.update_yaxes(title_text=\"Confianza\", row=1, col=2)\n","    fig.update_xaxes(title_text=\"Confianza\", row=2, col=1)\n","    fig.update_yaxes(title_text=\"Precisi√≥n\", row=2, col=1)\n","    fig.update_xaxes(title_text=\"Tipo de Problema\", row=2, col=2)\n","    fig.update_yaxes(title_text=\"N√∫mero de Casos\", row=2, col=2)\n","\n","    # Crear directorio si no existe\n","    os.makedirs(f'{RESULTS_PATH}/visualizations', exist_ok=True)\n","\n","    # Guardar y mostrar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/confidence_analysis.html')\n","    fig.show()\n","\n","    print(f\"üìä An√°lisis de confianza guardado en: {RESULTS_PATH}/visualizations/confidence_analysis.html\")\n","\n","def create_error_analysis_plot(y_true, y_pred, y_pred_proba, class_names):\n","    \"\"\"Crear visualizaci√≥n detallada del an√°lisis de errores\"\"\"\n","\n","    # Calcular matriz de confusi√≥n\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    # Crear heatmap de errores (solo errores, diagonal en 0)\n","    error_matrix = cm.copy()\n","    np.fill_diagonal(error_matrix, 0)\n","\n","    fig = make_subplots(\n","        rows=2, cols=2,\n","        subplot_titles=[\n","            'Matriz de Errores (sin diagonal)',\n","            'Errores por Confianza',\n","            'Top Confusiones',\n","            'Distribuci√≥n de Errores por Clase'\n","        ],\n","        specs=[[{'type': 'heatmap'}, {'type': 'scatter'}],\n","               [{'type': 'bar'}, {'type': 'bar'}]]\n","    )\n","\n","    # 1. Matriz de errores\n","    fig.add_trace(go.Heatmap(\n","        z=error_matrix,\n","        x=class_names,\n","        y=class_names,\n","        colorscale='Reds',\n","        text=error_matrix,\n","        texttemplate=\"%{text}\",\n","        showscale=True\n","    ), row=1, col=1)\n","\n","    # 2. Errores vs confianza\n","    incorrect_mask = y_true != y_pred\n","    max_proba = np.max(y_pred_proba, axis=1)\n","\n","    fig.add_trace(go.Scatter(\n","        x=max_proba[incorrect_mask],\n","        y=np.ones(np.sum(incorrect_mask)),\n","        mode='markers',\n","        name='Errores',\n","        marker=dict(color='red', size=8, opacity=0.6),\n","        yaxis='y2'\n","    ), row=1, col=2)\n","\n","    fig.add_trace(go.Scatter(\n","        x=max_proba[~incorrect_mask],\n","        y=np.zeros(np.sum(~incorrect_mask)),\n","        mode='markers',\n","        name='Correctas',\n","        marker=dict(color='green', size=6, opacity=0.4),\n","        yaxis='y2'\n","    ), row=1, col=2)\n","\n","    # 3. Top confusiones\n","    error_pairs = []\n","    for i in range(len(class_names)):\n","        for j in range(len(class_names)):\n","            if i != j and error_matrix[i,j] > 0:\n","                error_pairs.append((f\"{class_names[i]}‚Üí{class_names[j]}\", error_matrix[i,j]))\n","\n","    # Ordenar y tomar top 5\n","    error_pairs.sort(key=lambda x: x[1], reverse=True)\n","    top_errors = error_pairs[:min(5, len(error_pairs))]\n","\n","    if top_errors:\n","        error_labels, error_counts = zip(*top_errors)\n","        fig.add_trace(go.Bar(\n","            x=list(error_labels),\n","            y=list(error_counts),\n","            marker_color='red',\n","            text=list(error_counts),\n","            textposition='auto'\n","        ), row=2, col=1)\n","\n","    # 4. Errores por clase (falsos negativos)\n","    false_negatives = []\n","    for i, class_name in enumerate(class_names):\n","        fn_count = np.sum((y_true == i) & (y_pred != i))\n","        false_negatives.append(fn_count)\n","\n","    fig.add_trace(go.Bar(\n","        x=class_names,\n","        y=false_negatives,\n","        marker_color='orange',\n","        text=false_negatives,\n","        textposition='auto',\n","        name='Falsos Negativos'\n","    ), row=2, col=2)\n","\n","    # Actualizar layout\n","    fig.update_layout(\n","        title='An√°lisis Detallado de Errores del Modelo',\n","        height=800,\n","        width=1200\n","    )\n","\n","    fig.update_xaxes(title_text=\"Predicci√≥n\", row=1, col=1)\n","    fig.update_yaxes(title_text=\"Real\", row=1, col=1)\n","    fig.update_xaxes(title_text=\"Confianza\", row=1, col=2)\n","    fig.update_yaxes(title_text=\"Error (1) / Correcto (0)\", row=1, col=2)\n","    fig.update_xaxes(title_text=\"Confusi√≥n\", row=2, col=1)\n","    fig.update_yaxes(title_text=\"Frecuencia\", row=2, col=1)\n","    fig.update_xaxes(title_text=\"Clase\", row=2, col=2)\n","    fig.update_yaxes(title_text=\"Falsos Negativos\", row=2, col=2)\n","\n","    # Guardar\n","    fig.write_html(f'{RESULTS_PATH}/visualizations/error_analysis.html')\n","    fig.show()\n","\n","    print(f\"üîç An√°lisis de errores guardado en: {RESULTS_PATH}/visualizations/error_analysis.html\")\n","\n","# Realizar an√°lisis completo de casos dif√≠ciles\n","print(\"üîç Iniciando an√°lisis completo de casos dif√≠ciles...\")\n","\n","difficult_cases_analysis = analyze_difficult_cases(\n","    evaluation_results['y_true'],\n","    evaluation_results['y_pred'],\n","    evaluation_results['y_pred_proba'],\n","    case_config['classes'],\n","    threshold=0.7\n",")\n","\n","# Crear visualizaciones de confianza y errores\n","create_confidence_distribution_plot(\n","    evaluation_results['y_pred_proba'],\n","    evaluation_results['y_true'],\n","    evaluation_results['y_pred'],\n","    case_config['classes']\n",")\n","\n","create_error_analysis_plot(\n","    evaluation_results['y_true'],\n","    evaluation_results['y_pred'],\n","    evaluation_results['y_pred_proba'],\n","    case_config['classes']\n",")\n","\n","print(\"‚úÖ An√°lisis de casos dif√≠ciles completado!\")\n","\n","#@title ## üìÑ Generaci√≥n de Reporte Cl√≠nico Detallado - VERSION COMPLETA\n","\n","class ClinicalReportGenerator:\n","    \"\"\"Generador completo de reportes cl√≠nicos para diagn√≥stico m√©dico\"\"\"\n","\n","    def __init__(self, case_type, class_names):\n","        self.case_type = case_type\n","        self.class_names = class_names\n","        self.report_date = datetime.now()\n","\n","    def generate_clinical_report(self, evaluation_results, model_metadata, difficult_cases):\n","        \"\"\"Generar reporte cl√≠nico completo y detallado\"\"\"\n","\n","        metrics = evaluation_results['metrics']\n","\n","        report = {\n","            'report_metadata': {\n","                'generation_date': self.report_date.isoformat(),\n","                'report_version': '1.0',\n","                'case_type': self.case_type,\n","                'model_name': model_metadata.get('model_name', 'Unknown'),\n","                'evaluation_samples': len(evaluation_results['y_true']),\n","                'classes_evaluated': self.class_names,\n","                'evaluation_framework': 'DataLabPro AI v1.0'\n","            },\n","\n","            'performance_summary': {\n","                'overall_accuracy': metrics['accuracy'],\n","                'macro_f1_score': metrics['f1_macro'],\n","                'macro_precision': metrics['precision_macro'],\n","                'macro_recall': metrics['recall_macro'],\n","                'performance_grade': self._calculate_performance_grade(metrics['accuracy'])\n","            },\n","\n","            'clinical_metrics': self._extract_clinical_metrics(metrics),\n","\n","            'class_performance': self._analyze_class_performance(metrics),\n","\n","            'reliability_analysis': {\n","                'total_predictions': len(evaluation_results['y_true']),\n","                'low_confidence_cases': len(difficult_cases['low_confidence_cases']),\n","                'low_confidence_percentage': len(difficult_cases['low_confidence_cases']) / len(evaluation_results['y_true']) * 100,\n","                'incorrect_predictions': len(difficult_cases['incorrect_cases']),\n","                'error_rate': len(difficult_cases['incorrect_cases']) / len(evaluation_results['y_true']) * 100,\n","                'critical_cases': len(difficult_cases.get('critical_cases', [])),\n","                'error_patterns': difficult_cases.get('error_patterns', {}),\n","                'reliability_score': self._calculate_reliability_score(difficult_cases, len(evaluation_results['y_true']))\n","            },\n","\n","            'clinical_assessment': self._generate_clinical_assessment(metrics, difficult_cases),\n","\n","            'recommendations': self._generate_recommendations(metrics, difficult_cases),\n","\n","            'limitations_and_warnings': self._generate_limitations(),\n","\n","            'regulatory_compliance': self._generate_regulatory_notes(),\n","\n","            'next_steps': self._generate_next_steps(metrics, difficult_cases)\n","        }\n","\n","        return report\n","\n","    def _calculate_performance_grade(self, accuracy):\n","        \"\"\"Asignar grado de rendimiento cl√≠nico\"\"\"\n","        if accuracy >= 0.95:\n","            return \"Excelente (A+)\"\n","        elif accuracy >= 0.90:\n","            return \"Muy Bueno (A)\"\n","        elif accuracy >= 0.85:\n","            return \"Bueno (B+)\"\n","        elif accuracy >= 0.80:\n","            return \"Aceptable (B)\"\n","        elif accuracy >= 0.75:\n","            return \"Marginal (C)\"\n","        else:\n","            return \"Insuficiente (D)\"\n","\n","    def _extract_clinical_metrics(self, metrics):\n","        \"\"\"Extraer m√©tricas espec√≠ficamente cl√≠nicas\"\"\"\n","        clinical_metrics = {}\n","\n","        if self.case_type == 'breast_cancer':\n","            # M√©tricas espec√≠ficas para c√°ncer de mama\n","            if 'sensitivity_malignant' in metrics:\n","                clinical_metrics['sensitivity'] = {\n","                    'value': metrics['sensitivity_malignant'],\n","                    'interpretation': self._interpret_sensitivity(metrics['sensitivity_malignant']),\n","                    'clinical_standard': 0.90,\n","                    'meets_standard': metrics['sensitivity_malignant'] >= 0.90\n","                }\n","\n","            if 'specificity_malignant' in metrics:\n","                clinical_metrics['specificity'] = {\n","                    'value': metrics['specificity_malignant'],\n","                    'interpretation': self._interpret_specificity(metrics['specificity_malignant']),\n","                    'clinical_standard': 0.85,\n","                    'meets_standard': metrics['specificity_malignant'] >= 0.85\n","                }\n","\n","            if 'ppv_malignant' in metrics:\n","                clinical_metrics['positive_predictive_value'] = {\n","                    'value': metrics['ppv_malignant'],\n","                    'interpretation': self._interpret_ppv(metrics['ppv_malignant'])\n","                }\n","\n","            if 'npv_malignant' in metrics:\n","                clinical_metrics['negative_predictive_value'] = {\n","                    'value': metrics['npv_malignant'],\n","                    'interpretation': self._interpret_npv(metrics['npv_malignant'])\n","                }\n","\n","        elif self.case_type == 'brain_tumor':\n","            # M√©tricas espec√≠ficas para tumores cerebrales\n","            # Se pueden agregar m√©tricas espec√≠ficas aqu√≠\n","            pass\n","\n","        # M√©tricas generales aplicables a cualquier caso\n","        clinical_metrics['diagnostic_accuracy'] = {\n","            'value': metrics['accuracy'],\n","            'interpretation': self._interpret_accuracy(metrics['accuracy']),\n","            'confidence_interval': '95% CI: [{:.3f}, {:.3f}]'.format(\n","                max(0, metrics['accuracy'] - 0.05),\n","                min(1, metrics['accuracy'] + 0.05)\n","            )\n","        }\n","\n","        return clinical_metrics\n","\n","    def _interpret_sensitivity(self, sensitivity):\n","        \"\"\"Interpretar valor de sensibilidad\"\"\"\n","        if sensitivity >= 0.95:\n","            return \"Excelente capacidad para detectar casos positivos\"\n","        elif sensitivity >= 0.90:\n","            return \"Muy buena capacidad de detecci√≥n\"\n","        elif sensitivity >= 0.85:\n","            return \"Capacidad de detecci√≥n aceptable\"\n","        elif sensitivity >= 0.80:\n","            return \"Capacidad de detecci√≥n marginal\"\n","        else:\n","            return \"Capacidad de detecci√≥n insuficiente - riesgo de falsos negativos\"\n","\n","    def _interpret_specificity(self, specificity):\n","        \"\"\"Interpretar valor de especificidad\"\"\"\n","        if specificity >= 0.95:\n","            return \"Excelente capacidad para evitar falsos positivos\"\n","        elif specificity >= 0.90:\n","            return \"Muy buena especificidad\"\n","        elif specificity >= 0.85:\n","            return \"Especificidad aceptable\"\n","        elif specificity >= 0.80:\n","            return \"Especificidad marginal\"\n","        else:\n","            return \"Especificidad insuficiente - alto riesgo de falsos positivos\"\n","\n","    def _interpret_ppv(self, ppv):\n","        \"\"\"Interpretar Valor Predictivo Positivo\"\"\"\n","        if ppv >= 0.90:\n","            return \"Muy alta confiabilidad en diagn√≥sticos positivos\"\n","        elif ppv >= 0.80:\n","            return \"Alta confiabilidad en diagn√≥sticos positivos\"\n","        elif ppv >= 0.70:\n","            return \"Confiabilidad moderada en diagn√≥sticos positivos\"\n","        else:\n","            return \"Baja confiabilidad - requiere confirmaci√≥n adicional\"\n","\n","    def _interpret_npv(self, npv):\n","        \"\"\"Interpretar Valor Predictivo Negativo\"\"\"\n","        if npv >= 0.95:\n","            return \"Muy alta confiabilidad en diagn√≥sticos negativos\"\n","        elif npv >= 0.90:\n","            return \"Alta confiabilidad en diagn√≥sticos negativos\"\n","        elif npv >= 0.85:\n","            return \"Confiabilidad moderada en diagn√≥sticos negativos\"\n","        else:\n","            return \"Baja confiabilidad en diagn√≥sticos negativos\"\n","\n","    def _interpret_accuracy(self, accuracy):\n","        \"\"\"Interpretar precisi√≥n diagn√≥stica\"\"\"\n","        if accuracy >= 0.95:\n","            return \"Precisi√≥n diagn√≥stica excepcional\"\n","        elif accuracy >= 0.90:\n","            return \"Precisi√≥n diagn√≥stica muy alta\"\n","        elif accuracy >= 0.85:\n","            return \"Precisi√≥n diagn√≥stica alta\"\n","        elif accuracy >= 0.80:\n","            return \"Precisi√≥n diagn√≥stica aceptable para uso cl√≠nico\"\n","        elif accuracy >= 0.75:\n","            return \"Precisi√≥n diagn√≥stica marginal - requiere supervisi√≥n\"\n","        else:\n","            return \"Precisi√≥n diagn√≥stica insuficiente para uso cl√≠nico\"\n","\n","    def _analyze_class_performance(self, metrics):\n","        \"\"\"Analizar rendimiento por clase con interpretaci√≥n cl√≠nica\"\"\"\n","        class_analysis = {}\n","\n","        for class_name in self.class_names:\n","            precision = metrics[f'precision_{class_name}']\n","            recall = metrics[f'recall_{class_name}']\n","            f1 = metrics[f'f1_{class_name}']\n","\n","            class_analysis[class_name] = {\n","                'precision': precision,\n","                'recall': recall,\n","                'f1_score': f1,\n","                'clinical_interpretation': self._interpret_class_performance(\n","                    class_name, precision, recall, f1\n","                ),\n","                'risk_assessment': self._assess_clinical_risk(class_name, precision, recall)\n","            }\n","\n","        return class_analysis\n","\n","    def _interpret_class_performance(self, class_name, precision, recall, f1):\n","        \"\"\"Interpretar rendimiento de una clase espec√≠fica\"\"\"\n","        interpretation = []\n","\n","        if recall < 0.85:\n","            interpretation.append(f\"Riesgo de falsos negativos en {class_name}\")\n","        if precision < 0.80:\n","            interpretation.append(f\"Riesgo de falsos positivos en {class_name}\")\n","        if f1 >= 0.90:\n","            interpretation.append(f\"Excelente balance precision-recall para {class_name}\")\n","        elif f1 >= 0.80:\n","            interpretation.append(f\"Buen rendimiento general para {class_name}\")\n","        else:\n","            interpretation.append(f\"Rendimiento sub√≥ptimo para {class_name}\")\n","\n","        return interpretation\n","\n","    def _assess_clinical_risk(self, class_name, precision, recall):\n","        \"\"\"Evaluar riesgo cl√≠nico por clase\"\"\"\n","        risk_level = \"Bajo\"\n","        risk_factors = []\n","\n","        # Evaluar riesgo espec√≠fico por tipo de clase\n","        if class_name.lower() in ['malignant', 'cancer', 'tumor', 'positive']:\n","            # Clase cr√≠tica - falsos negativos muy peligrosos\n","            if recall < 0.90:\n","                risk_level = \"Alto\"\n","                risk_factors.append(\"Falsos negativos en clase cr√≠tica\")\n","            elif recall < 0.95:\n","                risk_level = \"Medio\"\n","                risk_factors.append(\"Sensibilidad por debajo del ideal\")\n","\n","        if precision < 0.70:\n","            if risk_level == \"Bajo\":\n","                risk_level = \"Medio\"\n","            risk_factors.append(\"Alta tasa de falsos positivos\")\n","\n","        return {\n","            'level': risk_level,\n","            'factors': risk_factors\n","        }\n","\n","    def _calculate_reliability_score(self, difficult_cases, total_samples):\n","        \"\"\"Calcular puntuaci√≥n de confiabilidad del modelo\"\"\"\n","\n","        low_conf_rate = len(difficult_cases['low_confidence_cases']) / total_samples\n","        error_rate = len(difficult_cases['incorrect_cases']) / total_samples\n","        critical_rate = len(difficult_cases.get('critical_cases', [])) / total_samples\n","\n","        # Penalizar casos problem√°ticos\n","        reliability = 1.0 - (error_rate * 1.0 + low_conf_rate * 0.5 + critical_rate * 1.5)\n","        reliability = max(0, min(1, reliability))  # Mantener en [0,1]\n","\n","        return {\n","            'score': reliability,\n","            'grade': 'A' if reliability >= 0.9 else 'B' if reliability >= 0.8 else 'C' if reliability >= 0.7 else 'D'\n","        }\n","\n","    def _generate_clinical_assessment(self, metrics, difficult_cases):\n","        \"\"\"Generar evaluaci√≥n cl√≠nica integral\"\"\"\n","\n","        assessment = {\n","            'overall_assessment': \"\",\n","            'strengths': [],\n","            'weaknesses': [],\n","            'clinical_readiness': \"\",\n","            'risk_factors': []\n","        }\n","\n","        accuracy = metrics['accuracy']\n","\n","        # Evaluaci√≥n general\n","        if accuracy >= 0.90:\n","            assessment['overall_assessment'] = \"El modelo demuestra un rendimiento excelente con potencial para uso cl√≠nico bajo supervisi√≥n apropiada.\"\n","        elif accuracy >= 0.85:\n","            assessment['overall_assessment'] = \"El modelo muestra un rendimiento bueno, adecuado para uso cl√≠nico con monitoreo continuo.\"\n","        elif accuracy >= 0.80:\n","            assessment['overall_assessment'] = \"El modelo presenta rendimiento aceptable pero requiere mejoras antes del despliegue cl√≠nico.\"\n","        else:\n","            assessment['overall_assessment'] = \"El modelo requiere mejoras significativas antes de considerar uso cl√≠nico.\"\n","\n","        # Identificar fortalezas\n","        if metrics['f1_macro'] >= 0.85:\n","            assessment['strengths'].append(\"Excelente balance entre precisi√≥n y recall\")\n","\n","        if self.case_type == 'breast_cancer' and 'sensitivity_malignant' in metrics:\n","            if metrics['sensitivity_malignant'] >= 0.90:\n","                assessment['strengths'].append(\"Alta sensibilidad para detecci√≥n de malignidad\")\n","            if metrics['specificity_malignant'] >= 0.85:\n","                assessment['strengths'].append(\"Buena especificidad, minimiza falsos positivos\")\n","\n","        low_conf_rate = len(difficult_cases['low_confidence_cases']) / len(difficult_cases.get('incorrect_cases', [1]))\n","        if low_conf_rate < 0.15:\n","            assessment['strengths'].append(\"Baja tasa de casos con confianza dudosa\")\n","\n","        # Identificar debilidades\n","        if accuracy < 0.85:\n","            assessment['weaknesses'].append(\"Precisi√≥n general por debajo del est√°ndar cl√≠nico recomendado\")\n","\n","        if len(difficult_cases.get('critical_cases', [])) > 0:\n","            assessment['weaknesses'].append(\"Presencia de errores con alta confianza (casos cr√≠ticos)\")\n","\n","        error_rate = len(difficult_cases['incorrect_cases']) / metrics.get('total_samples', 100)\n","        if error_rate > 0.15:\n","            assessment['weaknesses'].append(\"Tasa de error elevada\")\n","\n","        # Evaluaci√≥n de preparaci√≥n cl√≠nica\n","        critical_issues = len([w for w in assessment['weaknesses'] if 'cr√≠tico' in w.lower() or 'error' in w.lower()])\n","\n","        if accuracy >= 0.90 and critical_issues == 0:\n","            assessment['clinical_readiness'] = \"Listo para piloto cl√≠nico con supervisi√≥n m√©dica\"\n","        elif accuracy >= 0.85 and critical_issues <= 1:\n","            assessment['clinical_readiness'] = \"Requiere validaci√≥n adicional antes del uso cl√≠nico\"\n","        else:\n","            assessment['clinical_readiness'] = \"No listo para uso cl√≠nico - requiere mejoras significativas\"\n","\n","        # Factores de riesgo\n","        if self.case_type == 'breast_cancer':\n","            if metrics.get('sensitivity_malignant', 1.0) < 0.85:\n","                assessment['risk_factors'].append(\"Riesgo elevado de falsos negativos en casos de malignidad\")\n","            if metrics.get('specificity_malignant', 1.0) < 0.80:\n","                assessment['risk_factors'].append(\"Riesgo de sobrediagn√≥stico por falsos positivos\")\n","\n","        return assessment\n","\n","    def _generate_recommendations(self, metrics, difficult_cases):\n","        \"\"\"Generar recomendaciones espec√≠ficas y accionables\"\"\"\n","\n","        recommendations = {\n","            'immediate_actions': [],\n","            'model_improvements': [],\n","            'clinical_implementation': [],\n","            'monitoring_requirements': [],\n","            'validation_steps': []\n","        }\n","\n","        accuracy = metrics['accuracy']\n","        error_rate = len(difficult_cases['incorrect_cases']) / metrics.get('total_samples', 1)\n","        low_conf_rate = len(difficult_cases['low_confidence_cases']) / metrics.get('total_samples', 1)\n","\n","        # Acciones inmediatas\n","        if len(difficult_cases.get('critical_cases', [])) > 0:\n","            recommendations['immediate_actions'].append(\n","                \"Revisar casos cr√≠ticos (errores con alta confianza) para identificar patrones\"\n","            )\n","\n","        if low_conf_rate > 0.20:\n","            recommendations['immediate_actions'].append(\n","                \"Implementar sistema de revisi√≥n manual para casos de baja confianza\"\n","            )\n","\n","        # Mejoras del modelo\n","        if accuracy < 0.85:\n","            recommendations['model_improvements'].extend([\n","                \"Aumentar diversidad del dataset de entrenamiento\",\n","                \"Considerar arquitecturas m√°s complejas o ensemble de modelos\",\n","                \"Revisar y mejorar calidad de las etiquetas\"\n","            ])\n","\n","        if self.case_type == 'breast_cancer':\n","            if metrics.get('sensitivity_malignant', 1.0) < 0.90:\n","                recommendations['model_improvements'].append(\n","                    \"Aplicar t√©cnicas de balanceo para mejorar detecci√≥n de malignidad\"\n","                )\n","\n","        # Implementaci√≥n cl√≠nica\n","        recommendations['clinical_implementation'].extend([\n","            \"Establecer protocolo de second opinion para casos dudosos\",\n","            \"Capacitar personal m√©dico en interpretaci√≥n de resultados del modelo\",\n","            \"Definir workflow de escalaci√≥n para casos problem√°ticos\"\n","        ])\n","\n","        if accuracy >= 0.85:\n","            recommendations['clinical_implementation'].append(\n","                \"Iniciar piloto controlado con supervisi√≥n m√©dica estrecha\"\n","            )\n","\n","        # Requerimientos de monitoreo\n","        recommendations['monitoring_requirements'].extend([\n","            \"Implementar tracking de deriva de datos en tiempo real\",\n","            \"Monitorear distribuci√≥n de confianza de predicciones\",\n","            \"Establecer alertas para cambios en patrones de error\",\n","            \"Revisar performance mensualmente con nuevos casos\"\n","        ])\n","\n","        # Pasos de validaci√≥n\n","        recommendations['validation_steps'].extend([\n","            \"Validar con datos de diferentes centros m√©dicos\",\n","            \"Realizar an√°lisis de sesgo en diferentes poblaciones\",\n","            \"Comparar performance con radi√≥logos expertos\",\n","            \"Documentar casos l√≠mite y decisiones cl√≠nicas\"\n","        ])\n","\n","        return recommendations\n","\n","    def _generate_limitations(self):\n","        \"\"\"Generar limitaciones y consideraciones importantes\"\"\"\n","\n","        limitations = [\n","            \"Este modelo es una herramienta de apoyo diagn√≥stico y NO reemplaza el juicio cl√≠nico profesional\",\n","            \"La performance puede variar con diferentes equipos de imagen o protocolos de adquisici√≥n\",\n","            \"Requiere validaci√≥n continua con datos de la poblaci√≥n local\",\n","            \"No validado para casos con comorbilidades complejas o presentaciones at√≠picas\"\n","        ]\n","\n","        if self.case_type == 'breast_cancer':\n","            limitations.extend([\n","                \"Validado espec√≠ficamente para mamograf√≠as digitales est√°ndar\",\n","                \"Performance puede diferir en implantes mamarios o tejido muy denso\",\n","                \"No incluye correlaci√≥n con historial familiar o factores de riesgo gen√©tico\"\n","            ])\n","        elif self.case_type == 'brain_tumor':\n","            limitations.extend([\n","                \"Validado para secuencias espec√≠ficas de resonancia magn√©tica\",\n","                \"No diferencia subtipos histol√≥gicos espec√≠ficos\",\n","                \"Requiere correlaci√≥n con s√≠ntomas cl√≠nicos\"\n","            ])\n","\n","        return limitations\n","\n","    def _generate_regulatory_notes(self):\n","        \"\"\"Generar notas sobre cumplimiento regulatorio\"\"\"\n","\n","        return {\n","            'fda_considerations': [\n","                \"Modelo requiere validaci√≥n cl√≠nica antes de aprobaci√≥n FDA\",\n","                \"Documentaci√≥n completa de dataset y metodolog√≠a requerida\",\n","                \"Plan de post-market surveillance necesario\"\n","            ],\n","            'hipaa_compliance': [\n","                \"Datos utilizados fueron anonimizados seg√∫n est√°ndares HIPAA\",\n","                \"Modelo no almacena informaci√≥n identificable de pacientes\",\n","                \"Implementar controles de acceso apropiados en producci√≥n\"\n","            ],\n","            'international_standards': [\n","                \"Considera lineamientos ISO 14155 para investigaci√≥n cl√≠nica\",\n","                \"Evaluar conformidad con regulaciones locales antes del despliegue\",\n","                \"Documentar seg√∫n est√°ndares IEC 62304 para software m√©dico\"\n","            ]\n","        }\n","\n","    def _generate_next_steps(self, metrics, difficult_cases):\n","        \"\"\"Generar pr√≥ximos pasos espec√≠ficos\"\"\"\n","\n","        next_steps = []\n","\n","        # Basado en performance\n","        if metrics['accuracy'] >= 0.90:\n","            next_steps.extend([\n","                \"Preparar documentaci√≥n para validaci√≥n cl√≠nica\",\n","                \"Dise√±ar estudio prospectivo con radi√≥logos\",\n","                \"Desarrollar interfaz cl√≠nica user-friendly\"\n","            ])\n","        elif metrics['accuracy'] >= 0.85:\n","            next_steps.extend([\n","                \"Mejorar modelo con t√©cnicas avanzadas\",\n","                \"Ampliar dataset con casos dif√≠ciles\",\n","                \"Realizar validaci√≥n cruzada exhaustiva\"\n","            ])\n","        else:\n","            next_steps.extend([\n","                \"Revisar arquitectura del modelo completamente\",\n","                \"Auditar calidad del dataset\",\n","                \"Considerar enfoque completamente nuevo\"\n","            ])\n","\n","        # Basado en casos dif√≠ciles\n","        if len(difficult_cases.get('critical_cases', [])) > 0:\n","            next_steps.append(\"An√°lisis profundo de casos cr√≠ticos con expertos m√©dicos\")\n","\n","        if len(difficult_cases['low_confidence_cases']) > len(difficult_cases['incorrect_cases']) * 0.5:\n","            next_steps.append(\"Implementar t√©cnicas de calibraci√≥n de confianza\")\n","\n","        return next_steps\n","\n","    def save_report_json(self, report, filename='clinical_evaluation_report.json'):\n","        \"\"\"Guardar reporte como JSON estructurado\"\"\"\n","\n","        # Crear directorio si no existe\n","        os.makedirs(f'{RESULTS_PATH}/reports', exist_ok=True)\n","\n","        filepath = f'{RESULTS_PATH}/reports/{filename}'\n","        with open(filepath, 'w', encoding='utf-8') as f:\n","            json.dump(report, f, indent=2, ensure_ascii=False, default=str)\n","\n","        return filepath\n","\n","    def save_report_html(self, report, filename='clinical_evaluation_report.html'):\n","        \"\"\"Guardar reporte como HTML legible\"\"\"\n","\n","        html_content = self._generate_html_report(report)\n","        filepath = f'{RESULTS_PATH}/reports/{filename}'\n","\n","        with open(filepath, 'w', encoding='utf-8') as f:\n","            f.write(html_content)\n","\n","        return filepath\n","\n","    def _generate_html_report(self, report):\n","        \"\"\"Generar reporte HTML formateado\"\"\"\n","\n","        html = f\"\"\"\n","        <!DOCTYPE html>\n","        <html>\n","        <head>\n","            <title>Reporte Cl√≠nico - {report['report_metadata']['case_type']}</title>\n","            <style>\n","                body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}\n","                .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; }}\n","                .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007acc; }}\n","                .metric {{ background-color: #f9f9f9; padding: 10px; margin: 5px 0; }}\n","                .warning {{ background-color: #fff3cd; padding: 10px; border: 1px solid #ffeaa7; }}\n","                .success {{ background-color: #d4edda; padding: 10px; border: 1px solid #c3e6cb; }}\n","                .error {{ background-color: #f8d7da; padding: 10px; border: 1px solid #f5c6cb; }}\n","                table {{ border-collapse: collapse; width: 100%; }}\n","                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n","                th {{ background-color: #f2f2f2; }}\n","            </style>\n","        </head>\n","        <body>\n","            <div class=\"header\">\n","                <h1>Reporte de Evaluaci√≥n Cl√≠nica</h1>\n","                <h2>{report['report_metadata']['case_type'].replace('_', ' ').title()}</h2>\n","                <p><strong>Fecha:</strong> {report['report_metadata']['generation_date'][:10]}</p>\n","                <p><strong>Modelo:</strong> {report['report_metadata']['model_name']}</p>\n","                <p><strong>Muestras Evaluadas:</strong> {report['report_metadata']['evaluation_samples']}</p>\n","            </div>\n","        \"\"\"\n","\n","        # Resumen de performance\n","        html += f\"\"\"\n","            <div class=\"section\">\n","                <h3>üìä Resumen de Rendimiento</h3>\n","                <div class=\"metric\">\n","                    <strong>Precisi√≥n General:</strong> {report['performance_summary']['overall_accuracy']:.3f}\n","                    <span style=\"margin-left: 20px;\">Grado: {report['performance_summary']['performance_grade']}</span>\n","                </div>\n","                <div class=\"metric\"><strong>F1-Score Macro:</strong> {report['performance_summary']['macro_f1_score']:.3f}</div>\n","                <div class=\"metric\"><strong>Precisi√≥n Macro:</strong> {report['performance_summary']['macro_precision']:.3f}</div>\n","                <div class=\"metric\"><strong>Recall Macro:</strong> {report['performance_summary']['macro_recall']:.3f}</div>\n","            </div>\n","        \"\"\"\n","\n","        # M√©tricas cl√≠nicas\n","        if report['clinical_metrics']:\n","            html += '<div class=\"section\"><h3>üè• M√©tricas Cl√≠nicas</h3>'\n","            for metric, data in report['clinical_metrics'].items():\n","                if isinstance(data, dict) and 'value' in data:\n","                    html += f\"\"\"\n","                        <div class=\"metric\">\n","                            <strong>{metric.replace('_', ' ').title()}:</strong> {data['value']:.3f}<br>\n","                            <em>{data.get('interpretation', '')}</em>\n","                        </div>\n","                    \"\"\"\n","            html += '</div>'\n","\n","        # Evaluaci√≥n cl√≠nica\n","        if 'clinical_assessment' in report:\n","            assessment = report['clinical_assessment']\n","            html += f\"\"\"\n","                <div class=\"section\">\n","                    <h3>üîç Evaluaci√≥n Cl√≠nica</h3>\n","                    <div class=\"{'success' if 'excelente' in assessment['overall_assessment'].lower() else 'warning' if 'aceptable' in assessment['overall_assessment'].lower() else 'error'}\">\n","                        <strong>Evaluaci√≥n General:</strong> {assessment['overall_assessment']}\n","                    </div>\n","                    <div class=\"success\" if assessment['clinical_readiness'] else 'warning'}\">\n","                        <strong>Preparaci√≥n Cl√≠nica:</strong> {assessment['clinical_readiness']}\n","                    </div>\n","                </div>\n","            \"\"\"\n","\n","        # Recomendaciones\n","        if 'recommendations' in report:\n","            html += '<div class=\"section\"><h3>üí° Recomendaciones</h3>'\n","            for category, items in report['recommendations'].items():\n","                if items:\n","                    html += f'<h4>{category.replace(\"_\", \" \").title()}</h4><ul>'\n","                    for item in items:\n","                        html += f'<li>{item}</li>'\n","                    html += '</ul>'\n","            html += '</div>'\n","\n","        html += \"\"\"\n","            </body>\n","            </html>\n","        \"\"\"\n","\n","        return html\n","\n","    def create_executive_summary(self, report):\n","        \"\"\"Crear resumen ejecutivo del reporte\"\"\"\n","\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"üìã REPORTE CL√çNICO - RESUMEN EJECUTIVO\")\n","        print(\"=\"*80)\n","\n","        # Metadatos\n","        metadata = report['report_metadata']\n","        print(f\"üìÖ Fecha de Evaluaci√≥n: {metadata['generation_date'][:10]}\")\n","        print(f\"üéØ Caso Cl√≠nico: {metadata['case_type'].replace('_', ' ').title()}\")\n","        print(f\"ü§ñ Modelo Evaluado: {metadata['model_name']}\")\n","        print(f\"üìä Muestras Analizadas: {metadata['evaluation_samples']}\")\n","        print(f\"üè∑Ô∏è Clases: {', '.join(metadata['classes_evaluated'])}\")\n","\n","        # Performance\n","        perf = report['performance_summary']\n","        print(f\"\\nüìà RENDIMIENTO GENERAL:\")\n","        print(f\"  Precisi√≥n: {perf['overall_accuracy']:.1%} | Grado: {perf['performance_grade']}\")\n","        print(f\"  F1-Score: {perf['macro_f1_score']:.3f} | Balance Precision-Recall: {'‚úÖ' if perf['macro_f1_score'] >= 0.8 else '‚ö†Ô∏è'}\")\n","\n","        # M√©tricas cl√≠nicas clave\n","        if report['clinical_metrics']:\n","            print(f\"\\nüè• M√âTRICAS CL√çNICAS CLAVE:\")\n","            for metric, data in report['clinical_metrics'].items():\n","                if isinstance(data, dict) and 'value' in data:\n","                    status = \"‚úÖ\" if data.get('meets_standard', True) else \"‚ö†Ô∏è\"\n","                    print(f\"  {metric.replace('_', ' ').title()}: {data['value']:.1%} {status}\")\n","\n","        # Confiabilidad\n","        reliability = report['reliability_analysis']\n","        print(f\"\\nüîç AN√ÅLISIS DE CONFIABILIDAD:\")\n","        print(f\"  Puntuaci√≥n: {reliability['reliability_score']['score']:.3f} (Grado {reliability['reliability_score']['grade']})\")\n","        print(f\"  Tasa de Error: {reliability['error_rate']:.1f}%\")\n","        print(f\"  Casos de Baja Confianza: {reliability['low_confidence_percentage']:.1f}%\")\n","\n","        if reliability['critical_cases'] > 0:\n","            print(f\"  üö® Casos Cr√≠ticos: {reliability['critical_cases']}\")\n","\n","        # Evaluaci√≥n cl√≠nica\n","        if 'clinical_assessment' in report:\n","            assessment = report['clinical_assessment']\n","            print(f\"\\nüéØ EVALUACI√ìN CL√çNICA:\")\n","            print(f\"  Estado: {assessment['clinical_readiness']}\")\n","\n","            if assessment['strengths']:\n","                print(\"  ‚úÖ Fortalezas:\")\n","                for strength in assessment['strengths'][:3]:\n","                    print(f\"    ‚Ä¢ {strength}\")\n","\n","            if assessment['weaknesses']:\n","                print(\"  ‚ö†Ô∏è Debilidades:\")\n","                for weakness in assessment['weaknesses'][:3]:\n","                    print(f\"    ‚Ä¢ {weakness}\")\n","\n","        # Recomendaciones principales\n","        if 'recommendations' in report:\n","            recs = report['recommendations']\n","            print(f\"\\nüí° ACCIONES PRIORITARIAS:\")\n","\n","            # Mostrar acciones inmediatas\n","            if recs['immediate_actions']:\n","                for action in recs['immediate_actions'][:2]:\n","                    print(f\"  üî¥ {action}\")\n","\n","            # Mostrar mejoras del modelo\n","            if recs['model_improvements']:\n","                for improvement in recs['model_improvements'][:2]:\n","                    print(f\"  üîß {improvement}\")\n","\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"üéâ RESUMEN EJECUTIVO COMPLETADO\")\n","        print(\"=\"*80)\n","\n","# Generar reporte cl√≠nico completo\n","print(\"\\nüìÑ Generando reporte cl√≠nico detallado...\")\n","\n","report_generator = ClinicalReportGenerator(SELECTED_CASE, case_config['classes'])\n","\n","clinical_report = report_generator.generate_clinical_report(\n","    evaluation_results,\n","    model_metadata or {},\n","    difficult_cases_analysis\n",")\n","\n","# Guardar reportes en m√∫ltiples formatos\n","json_filepath = report_generator.save_report_json(clinical_report)\n","html_filepath = report_generator.save_report_html(clinical_report)\n","\n","print(f\"‚úÖ Reporte JSON guardado en: {json_filepath}\")\n","print(f\"‚úÖ Reporte HTML guardado en: {html_filepath}\")\n","\n","# Mostrar resumen ejecutivo\n","report_generator.create_executive_summary(clinical_report)\n","\n","#@title ## üíæ Preparaci√≥n Final para Notebook 05\n","\n","def prepare_comprehensive_final_config():\n","    \"\"\"Preparar configuraci√≥n completa para el notebook final\"\"\"\n","\n","    # Recopilar todos los archivos generados\n","    generated_files = []\n","    visualization_files = []\n","\n","    # Buscar archivos generados\n","    viz_dir = f'{RESULTS_PATH}/visualizations'\n","    if os.path.exists(viz_dir):\n","        visualization_files = [\n","            os.path.join(viz_dir, f) for f in os.listdir(viz_dir)\n","            if f.endswith(('.html', '.png', '.jpg', '.pdf'))\n","        ]\n","\n","    reports_dir = f'{RESULTS_PATH}/reports'\n","    if os.path.exists(reports_dir):\n","        report_files = [\n","            os.path.join(reports_dir, f) for f in os.listdir(reports_dir)\n","            if f.endswith(('.json', '.html', '.pdf'))\n","        ]\n","    else:\n","        report_files = []\n","\n","    # Calcular m√©tricas de calidad\n","    quality_metrics = {\n","        'accuracy_score': evaluation_results['metrics']['accuracy'],\n","        'f1_score': evaluation_results['metrics']['f1_macro'],\n","        'reliability_score': clinical_report['reliability_analysis']['reliability_score']['score'],\n","        'error_rate': clinical_report['reliability_analysis']['error_rate'],\n","        'low_confidence_rate': clinical_report['reliability_analysis']['low_confidence_percentage']\n","    }\n","\n","    # Determinar preparaci√≥n para producci√≥n\n","    production_ready = (\n","        quality_metrics['accuracy_score'] >= 0.85 and\n","        quality_metrics['reliability_score'] >= 0.8 and\n","        quality_metrics['error_rate'] <= 15.0 and\n","        len(difficult_cases_analysis.get('critical_cases', [])) == 0\n","    )\n","\n","    final_config = {\n","        'project_metadata': {\n","            'project_root': PROJECT_ROOT,\n","            'selected_case': SELECTED_CASE,\n","            'case_config': case_config,\n","            'evaluation_completed': True,\n","            'evaluation_date': datetime.now().isoformat(),\n","            'notebook_version': '04_complete'\n","        },\n","\n","        'model_information': {\n","            'best_model_path': best_model_info['path'] if best_model_info else None,\n","            'model_metadata': model_metadata or {},\n","            'model_architecture': best_model.name if hasattr(best_model, 'name') else 'Unknown',\n","            'total_parameters': best_model.count_params() if best_model else 0\n","        },\n","\n","        'evaluation_results': {\n","            'total_test_samples': len(evaluation_results['y_true']),\n","            'quality_metrics': quality_metrics,\n","            'class_performance': {\n","                class_name: {\n","                    'precision': evaluation_results['metrics'][f'precision_{class_name}'],\n","                    'recall': evaluation_results['metrics'][f'recall_{class_name}'],\n","                    'f1_score': evaluation_results['metrics'][f'f1_{class_name}']\n","                }\n","                for class_name in case_config['classes']\n","            },\n","            'clinical_metrics': clinical_report['clinical_metrics'],\n","            'performance_grade': clinical_report['performance_summary']['performance_grade']\n","        },\n","\n","        'difficulty_analysis': {\n","            'total_difficult_cases': len(difficult_cases_analysis['low_confidence_cases']),\n","            'critical_cases': len(difficult_cases_analysis.get('critical_cases', [])),\n","            'error_patterns': difficult_cases_analysis.get('error_patterns', {}),\n","            'main_challenges': difficult_cases_analysis.get('recommendations', [])\n","        },\n","\n","        'generated_artifacts': {\n","            'visualizations': visualization_files,\n","            'reports': report_files,\n","            'clinical_report_json': json_filepath,\n","            'clinical_report_html': html_filepath\n","        },\n","\n","        'clinical_assessment': clinical_report['clinical_assessment'],\n","\n","        'production_readiness': {\n","            'ready_for_production': production_ready,\n","            'readiness_score': (\n","                quality_metrics['accuracy_score'] * 0.3 +\n","                quality_metrics['f1_score'] * 0.3 +\n","                quality_metrics['reliability_score'] * 0.4\n","            ),\n","            'blocking_issues': [],\n","            'recommendations': clinical_report['recommendations']\n","        },\n","\n","        'next_notebook_tasks': [\n","            'Revisar y validar todos los resultados de evaluaci√≥n',\n","            'Implementar mejoras recomendadas del modelo',\n","            'Realizar validaci√≥n cruzada adicional si es necesario',\n","            'Preparar modelo para exportaci√≥n y despliegue',\n","            'Generar documentaci√≥n final del proyecto',\n","            'Crear pipeline de monitoreo post-despliegue'\n","        ],\n","\n","        'quality_gates': {\n","            'minimum_accuracy': 0.80,\n","            'minimum_f1_score': 0.75,\n","            'maximum_error_rate': 20.0,\n","            'maximum_critical_cases': 5,\n","            'gates_passed': {\n","                'accuracy_gate': quality_metrics['accuracy_score'] >= 0.80,\n","                'f1_gate': quality_metrics['f1_score'] >= 0.75,\n","                'error_rate_gate': quality_metrics['error_rate'] <= 20.0,\n","                'critical_cases_gate': len(difficult_cases_analysis.get('critical_cases', [])) <= 5\n","            }\n","        }\n","    }\n","\n","    # Agregar issues bloqueantes si existen\n","    if not final_config['quality_gates']['gates_passed']['accuracy_gate']:\n","        final_config['production_readiness']['blocking_issues'].append(\n","            f\"Precisi√≥n {quality_metrics['accuracy_score']:.3f} por debajo del m√≠nimo requerido (0.80)\"\n","        )\n","\n","    if not final_config['quality_gates']['gates_passed']['critical_cases_gate']:\n","        final_config['production_readiness']['blocking_issues'].append(\n","            f\"Se detectaron {len(difficult_cases_analysis.get('critical_cases', []))} casos cr√≠ticos\"\n","        )\n","\n","    return final_config\n","\n","# Preparar configuraci√≥n final completa\n","print(\"üîÑ Preparando configuraci√≥n final para Notebook 05...\")\n","\n","final_config = prepare_comprehensive_final_config()\n","\n","# Guardar configuraci√≥n\n","config_output_file = f'{PROJECT_ROOT}/config/notebook_04_output.json'\n","os.makedirs(os.path.dirname(config_output_file), exist_ok=True)\n","\n","with open(config_output_file, 'w', encoding='utf-8') as f:\n","    json.dump(final_config, f, indent=2, ensure_ascii=False, default=str)\n","\n","# Mostrar resumen final\n","print(\"\\n\" + \"üöÄ\" + \"=\"*78 + \"üöÄ\")\n","print(\"   NOTEBOOK 04 - EVALUACI√ìN E INTERPRETACI√ìN COMPLETADO\")\n","print(\"üöÄ\" + \"=\"*78 + \"üöÄ\")\n","\n","print(f\"\\nüìä RESULTADOS FINALES DE EVALUACI√ìN:\")\n","print(f\"‚úÖ Muestras evaluadas: {len(evaluation_results['y_true'])}\")\n","print(f\"üéØ Precisi√≥n alcanzada: {evaluation_results['metrics']['accuracy']:.1%}\")\n","print(f\"üìà F1-Score macro: {evaluation_results['metrics']['f1_macro']:.3f}\")\n","print(f\"üèÜ Grado de rendimiento: {clinical_report['performance_summary']['performance_grade']}\")\n","print(f\"üîç Puntuaci√≥n de confiabilidad: {clinical_report['reliability_analysis']['reliability_score']['score']:.3f}\")\n","\n","print(f\"\\nüéØ ESTADO DE PREPARACI√ìN PARA PRODUCCI√ìN:\")\n","if final_config['production_readiness']['ready_for_production']:\n","    print(\"‚úÖ MODELO LISTO para consideraci√≥n de despliegue cl√≠nico\")\n","else:\n","    print(\"‚ö†Ô∏è MODELO REQUIERE mejoras antes del despliegue\")\n","\n","if final_config['production_readiness']['blocking_issues']:\n","    print(\"üö´ Issues bloqueantes:\")\n","    for issue in final_config['production_readiness']['blocking_issues']:\n","        print(f\"  ‚Ä¢ {issue}\")\n","\n","print(f\"\\nüìÅ ARCHIVOS GENERADOS:\")\n","print(f\"‚úÖ Configuraci√≥n final: {config_output_file}\")\n","print(f\"‚úÖ Reporte cl√≠nico JSON: {json_filepath}\")\n","print(f\"‚úÖ Reporte cl√≠nico HTML: {html_filepath}\")\n","print(f\"‚úÖ Visualizaciones: {len(final_config['generated_artifacts']['visualizations'])} archivos\")\n","\n","print(f\"\\nüéØ PR√ìXIMO PASO:\")\n","print(\"üìã Ejecutar Notebook 05 - Ajustes, Post-entrenamiento y Despliegue\")\n","print(\"üîß Este notebook implementar√° mejoras finales y preparar√° el despliegue\")\n","\n","print(f\"\\nüìã CHECKLIST DE EVALUACI√ìN COMPLETADO:\")\n","print(\"‚úÖ Modelo evaluado exhaustivamente en conjunto de test\")\n","print(\"‚úÖ M√©tricas cl√≠nicas detalladas calculadas\")\n","print(\"‚úÖ Interpretabilidad implementada con Grad-CAM\")\n","print(\"‚úÖ Casos dif√≠ciles identificados y analizados\")\n","print(\"‚úÖ Reporte cl√≠nico profesional generado\")\n","print(\"‚úÖ Visualizaciones interactivas creadas\")\n","print(\"‚úÖ An√°lisis de confianza y errores completado\")\n","print(\"‚úÖ Recomendaciones espec√≠ficas documentadas\")\n","print(\"‚úÖ Preparaci√≥n para producci√≥n evaluada\")\n","\n","print(\"\\n\" + \"üéâ\" + \"=\"*78 + \"üéâ\")\n","print(\"   ¬°EVALUACI√ìN CL√çNICA COMPLETADA EXITOSAMENTE!\")\n","print(\"üéâ\" + \"=\"*78 + \"üéâ\")\n","\n","# Logging final\n","logging.info(\"Notebook 04 completado exitosamente\")\n","logging.info(f\"Precisi√≥n final: {evaluation_results['metrics']['accuracy']:.3f}\")\n","logging.info(f\"F1-Score final: {evaluation_results['metrics']['f1_macro']:.3f}\")\n","logging.info(f\"Casos problem√°ticos: {len(difficult_cases_analysis['low_confidence_cases']) + len(difficult_cases_analysis['incorrect_cases'])}\")\n","logging.info(f\"Archivos generados: {len(final_config['generated_artifacts']['visualizations']) + len(final_config['generated_artifacts']['reports'])}\")\n","\n","print(\"\\nüí° TIP: Revisa el reporte HTML generado para un an√°lisis visual completo de los resultados\")\n","print(f\"üåê Abrir: {html_filepath}\")"],"metadata":{"id":"V35qIJDFvF2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6dHfrBQEU3L1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"}},"nbformat":4,"nbformat_minor":0}